# =============================================================================
# Docker Cron Scheduling (for automated runs in Docker)
# =============================================================================

# Job scraper schedule (default: daily at 5 AM)
# Format: minute hour day month weekday
CRON_SCHEDULE_SCRAPER=0 5 * * *

# Job matcher schedule (default: daily at 5:30 AM)
CRON_SCHEDULE_MATCHER=30 5 * * *

# Enable/disable automated cron jobs
ENABLE_SCRAPER_CRON=true
ENABLE_MATCHER_CRON=true

# Timezone for cron scheduling
TZ=America/Denver

# =============================================================================
# IPRoyal Proxy Configuration
# =============================================================================

# Enable/disable proxy usage
# Set to false to use your local network directly (no proxy)
# Set to true to use IPRoyal proxy (requires credentials below)
USE_PROXY=true

IPROYAL_HOST=
IPROYAL_PORT=
IPROYAL_USERNAME=
IPROYAL_PASSWORD=

# Constructed proxy URL (used by core)
# Format: http://username:password@host:port
# Note: Session parameters are added dynamically by the scraper for IP rotation
PROXY_URL=

# =============================================================================
# Job Search Configuration
# =============================================================================

# Job titles to search for (now configured in templates/requirements.yaml under search_jobs)
# JOBS=['payroll manager', 'senior payroll specialist', 'senior payroll analyst', 'payroll operations lead', 'payroll consultant', 'payroll supervisor', 'senior payroll coordinator']

# Locations to search in (now configured in templates/requirements.yaml under search_locations)
# LOCATIONS=['Remote']

# Number of results to fetch per job/location combination
# Note: Each 100 results = ~1 API request
RESULTS_PER_SEARCH=500

# Output format: csv, json, or both
OUTPUT_FORMAT=both

# Remove duplicate job postings based on URL
DEDUPLICATE=true

# IP Rotation for comprehensive job discovery
# Run each search multiple times with different proxy IPs to capture location-based variations
# Example: With 8 jobs × 1 location × 3 IPs = 24 total searches
# Bandwidth: ~1.2 MB for 3 IPs, ~2.0 MB for 5 IPs
PROXY_ROTATION_COUNT=2

# =============================================================================
# Rate Limiting
# =============================================================================

# Delay between requests in seconds (default: 2.5)
# Increase if you're getting rate limited
RATE_LIMIT_DELAY=2.5

# =============================================================================
# Testing Configuration (Optional)
# =============================================================================

# Set to true for test mode with additional logging
TEST_MODE=false

# Maximum requests per session (safety limit, 0 = unlimited)
MAX_REQUESTS_PER_SESSION=0

# =============================================================================
# AI Job Matcher Configuration
# =============================================================================

# llama-server URL
LLAMA_SERVER_URL=[http://localhost:8080, http://host.docker.internal:8080]


# Path to the GGUF model file
LLAMA_MODEL_PATH=C:\models\Qwen3-30B-A3B-Instruct-2507\Qwen3-30B-A3B-Instruct-2507-Q6_K.gguf

# Model parameters
LLAMA_CONTEXT_SIZE=8192
LLAMA_TEMPERATURE=0.3
LLAMA_MAX_TOKENS=2560

# Job Matching Configuration
RESUME_PATH=templates/resume.txt
REQUIREMENTS_PATH=templates/requirements.yaml
MIN_MATCH_SCORE=60
REPORT_OUTPUT_DIR=reports/

# Multi-threading Configuration
# Number of parallel threads for job matching (scoring, analysis, optimization)
# Recommended: 4-8 threads for optimal performance
# Higher values = faster processing but more CPU/memory usage
# Set to 1 to disable multi-threading
MATCH_THREADS=4

# Job Tracker Database
JOB_TRACKER_DB=data/job_tracker.db

# Failure Tracker Database
# Tracks failed jobs for retry and analysis
FAILURE_TRACKER_DB=data/job_failures.db

# =============================================================================
# Deterministic Filters Configuration (NEW - Enhanced Filtering)
# =============================================================================
# Enable/disable individual pre-filters for faster job screening
# Pre-filters run BEFORE AI scoring to eliminate irrelevant jobs
# Benefits: 50-70% faster processing, fewer API calls, lower costs

# Deterministic Filters (set to true/false)
FILTER_TITLE_ENABLED=true
FILTER_SALARY_ENABLED=False
FILTER_LOCATION_ENABLED=false
FILTER_REMOTE_ENABLED=true
FILTER_JOB_TYPE_ENABLED=true
FILTER_COMPANY_SIZE_ENABLED=false
FILTER_POSTING_AGE_ENABLED=true

# Maximum job posting age in days (jobs older than this will be filtered out)
MAX_JOB_AGE_DAYS=30

# =============================================================================
# Retry Configuration (for failed jobs)
# =============================================================================

# Override temperature for retry attempts (higher = more creative responses)
# Default: uses LLAMA_TEMPERATURE if not set
# Recommended: 0.5-0.7 for retries (higher than normal processing)
# RETRY_TEMPERATURE=0.5

# Override max_tokens for retry attempts (more tokens = longer responses)
# Default: uses LLAMA_MAX_TOKENS if not set
# Recommended: 4096 for complex jobs that failed with validation errors
# RETRY_MAX_TOKENS=4096

# Maximum retry attempts per job before marking as permanently failed
# RETRY_MAX_ATTEMPTS=3

# Delay between retry attempts in seconds
# RETRY_DELAY_SECONDS=5

# =============================================================================
# Email Configuration
# =============================================================================

# Enable/disable automatic email delivery of reports
EMAIL_ENABLED='true'

# Email address to send reports to (configure with: python setup_email.py)
EMAIL_RECIPIENT=''

# Send email automatically when pipeline completes (requires EMAIL_ENABLED=true)
EMAIL_SEND_ON_COMPLETION='true'

# Only send email if at least this many matches are found
EMAIL_MIN_MATCHES='1'

# Email subject line prefix
EMAIL_SUBJECT_PREFIX='Job Report'
